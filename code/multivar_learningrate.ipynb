{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studying Learningrate\n",
    "In this Notebook, a study on learning-rate dependance on the different RNN-cells will be performed. The intention is to study their behavior to a change in the learningrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 01:33:51.217799: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-16 01:33:51.217835: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MSE\n",
    "from cmcrameri import cm\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from common import *\n",
    "from models import *\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Structuring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/input_data/MAIN_DATASET.csv\")\n",
    "\n",
    "price = df['NO2_price'].values.reshape(-1,1)\n",
    "fload = df['NO2_load_forecasted'].values.reshape(-1,1)\n",
    "fgen = df['NO2_generation_forecast'].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "price_days = seperate_column_to_days(price)\n",
    "fload_days = seperate_column_to_days(fload)\n",
    "fgen_days = seperate_column_to_days(fgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookbehind = 7\n",
    "input_width = lookbehind*24\n",
    "horizon = 24\n",
    "no_hours = input_width + horizon\n",
    "hour_in_days = int(no_hours / 24)\n",
    "\n",
    "price_dataset = []\n",
    "aload_dataset = []\n",
    "fload_dataset = []\n",
    "fgen_dataset = []\n",
    "agen_dataset = []\n",
    "\n",
    "for i in range(len(price_days) - hour_in_days+1):\n",
    "    price_dataset.append(np.concatenate((price_days[i:i+hour_in_days])))\n",
    "    fload_dataset.append(np.concatenate((fload_days[i:i+hour_in_days])))\n",
    "    fgen_dataset.append(np.concatenate((fgen_days[i:i+hour_in_days])))\n",
    "\n",
    "price_dataset = np.array(price_dataset)\n",
    "fload_dataset = np.array(fload_dataset)\n",
    "fgen_dataset = np.array(fgen_dataset)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "price_dataset = scaler.fit_transform(price_dataset[:,:,0])\n",
    "price_dataset = price_dataset[..., np.newaxis].astype(np.float32)\n",
    "\n",
    "fload_dataset = scaler.fit_transform(fload_dataset[:,:,0])\n",
    "fload_dataset = fload_dataset[..., np.newaxis].astype(np.float32)\n",
    "\n",
    "fgen_dataset = scaler.fit_transform(fgen_dataset[:,:,0])\n",
    "fgen_dataset = fgen_dataset[..., np.newaxis].astype(np.float32)\n",
    "\n",
    "dataset = np.concatenate((price_dataset, fload_dataset, fgen_dataset), axis=2)\n",
    "\n",
    "n,m,k = dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = int(0.7*n)\n",
    "valid = int(0.9*n)\n",
    "X_train = dataset[:train, :input_width]\n",
    "X_valid = dataset[train:valid, :input_width]\n",
    "X_test = dataset[valid:, :input_width]\n",
    "\n",
    "Y = np.empty((n, input_width, horizon))\n",
    "for step_ahead in range(1, horizon + 1):\n",
    "    Y[:,:, step_ahead - 1] = dataset[:,step_ahead:step_ahead + input_width, 0]\n",
    "\n",
    "Y_train = Y[:train]\n",
    "Y_valid = Y[train:valid]\n",
    "Y_test = Y[valid:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the models, based on optimal architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 01:33:52.474444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-12-16 01:33:52.474556: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-16 01:33:52.474602: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-16 01:33:52.474645: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-16 01:33:52.474686: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2021-12-16 01:33:52.474726: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2021-12-16 01:33:52.474767: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-16 01:33:52.474807: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-16 01:33:52.474847: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-12-16 01:33:52.474854: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-16 01:33:52.475260: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "rnn = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(128, return_sequences=True, input_shape=[None, k]),\n",
    "    keras.layers.SimpleRNN(128, return_sequences=True),\n",
    "    keras.layers.Dense(horizon)\n",
    "])\n",
    "\n",
    "lstm = keras.models.Sequential([\n",
    "    keras.layers.LSTM(128, return_sequences=True, input_shape=[None, k]),\n",
    "    keras.layers.LSTM(128, return_sequences=True),\n",
    "    keras.layers.Dense(horizon)\n",
    "])\n",
    "\n",
    "gru = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, k]),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.Dense(horizon)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningrates = np.array([0.005, 0.001, 0.0001, 0.00001])\n",
    "epochs = 10\n",
    "\n",
    "mse_list_lr = np.zeros((3, len(learningrates)))\n",
    "best_mse_lr = np.inf*np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Found new best SimpleRNN mse 0.10140297433021782\n",
      "Found new best LSTM mse 0.6294298753406561\n",
      "Found new best GRU mse 0.06535617283303269\n",
      "iteration 1\n",
      "Found new best SimpleRNN mse 0.08898579034502778\n",
      "Found new best LSTM mse 0.09092308257680885\n",
      "Found new best GRU mse 0.05924211464948325\n",
      "iteration 2\n",
      "Found new best SimpleRNN mse 0.0829224189929994\n",
      "Found new best LSTM mse 0.09018092957844777\n",
      "Found new best GRU mse 0.05751481096956626\n",
      "iteration 3\n",
      "Found new best SimpleRNN mse 0.0803784534568658\n",
      "Found new best LSTM mse 0.08948957497538874\n",
      "Found new best GRU mse 0.05709166368277968\n"
     ]
    }
   ],
   "source": [
    "for i, lr in enumerate(learningrates):\n",
    "    print(f\"iteration {i}\")\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    rnn.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    lstm.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    gru.compile(loss=\"mse\", optimizer=optimizer)\n",
    "\n",
    "    rnn.fit(X_train, Y_train, epochs=epochs, validation_data=(X_valid, Y_valid), verbose=False)\n",
    "    lstm.fit(X_train, Y_train, epochs=epochs, validation_data=(X_valid, Y_valid), verbose=False)\n",
    "    gru.fit(X_train, Y_train, epochs=epochs, validation_data=(X_valid, Y_valid), verbose=False)\n",
    "\n",
    "    Y_pred_rnn = rnn.predict(X_test)\n",
    "    Y_pred_lstm = lstm.predict(X_test)\n",
    "    Y_pred_gru = gru.predict(X_test)\n",
    "\n",
    "    mse_rnn = MSE(Y_test[:,-1], Y_pred_rnn[:,-1])\n",
    "    mse_lstm = MSE(Y_test[:,-1], Y_pred_lstm[:,-1])\n",
    "    mse_gru = MSE(Y_test[:,-1], Y_pred_gru[:,-1])\n",
    "\n",
    "    if mse_rnn < best_mse_lr[0]:\n",
    "        print(f\"Found new best SimpleRNN mse {mse_rnn}\")\n",
    "        best_mse_lr[0] = mse_rnn\n",
    "        fname = f\"../data/models/multivariate_lr_large_rnn.h5\"\n",
    "        keras.models.save_model(rnn, fname)\n",
    "\n",
    "    if mse_lstm < best_mse_lr[1]:\n",
    "        print(f\"Found new best LSTM mse {mse_lstm}\")\n",
    "        best_mse_lr[1] = mse_lstm\n",
    "        fname = f\"../data/models/multivariate_lr_large_lstm.h5\"\n",
    "        keras.models.save_model(lstm, fname)\n",
    "\n",
    "    if mse_gru < best_mse_lr[2]:\n",
    "        print(f\"Found new best GRU mse {mse_gru}\")\n",
    "        best_mse_lr[2] = mse_gru\n",
    "        fname = f\"../data/models/multivariate_lr_large_gru.h5\"\n",
    "        keras.models.save_model(gru, fname)\n",
    "\n",
    "    mse_list_lr[0,i] = mse_rnn\n",
    "    mse_list_lr[1,i] = mse_lstm\n",
    "    mse_list_lr[2,i] = mse_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_224/4291439478.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_list_lr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SimpleRNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_list_lr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LSTM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_list_lr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GRU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearningrates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(mse_list_lr[0], '.--', markersize=20, label=\"SimpleRNN\")\n",
    "plt.plot(mse_list_lr[1], '.--', markersize=20, label=\"LSTM\")\n",
    "plt.plot(mse_list_lr[2], '.--', markersize=20, label=\"GRU\")\n",
    "plt.xticks(ticks = np.arange(4), labels=learningrates)\n",
    "plt.xlabel(f\"Learningrate\")\n",
    "plt.ylabel(f\"Mean Squared Error\")\n",
    "#plt.ylim(0,0.15)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig(f\"../figures/multivariate_forecast_lr_grid_search.pdf\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

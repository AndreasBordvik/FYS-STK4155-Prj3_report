{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from statsmodels.regression.linear_model import yule_walker\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(f\"../data/input_data/MAIN_DATASET.csv\", index_col=[0])\n",
    "# df['year'] = pd.DatetimeIndex(df['date_time']).year\n",
    "# df['month'] = pd.DatetimeIndex(df['date_time']).month\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_test(df:pd.DataFrame, area:int)->None:\n",
    "    result = adfuller(df[f\"NO{area}_price\"])\n",
    "    df.head()\n",
    "    #print(result)\n",
    "    p_value = result[1]\n",
    "    if p_value < 0.005: \n",
    "        print(f\"{p_value=}<0.05,Data series is theoretically stationary\")\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        print(f\"{p_value=}, data need differencing\")\n",
    "        df[\"NO2_price_diff\"] = df[f\"NO{area}_price\"].diff()\n",
    "        df = df.dropna()\n",
    "        return df\n",
    "         \n",
    "df = hypothesis_test(df, 2)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "time_steps = 24\n",
    "order = 24\n",
    "\n",
    "train= df[\"NO2_price\"][:int(len(df)*0.9)].to_numpy()\n",
    "# train = df[\"NO2_price_diff\"][:-time_steps].to_numpy()\n",
    "\n",
    "test = df[\"NO2_price\"][int(len(df)*0.9):].to_numpy()\n",
    "#slice som vals to split into equal arrays of 24 hours:\n",
    "test = test[len(test)%24:]\n",
    "\n",
    "# print(f\"{len(train)=}\")\n",
    "# print(f\"{len(test)=}\")\n",
    "test_days = np.array_split(test, (len(test)/24))\n",
    "\n",
    "\n",
    "def AR_model(train:np.ndarray,test:list, time_steps:int,model_order:int, pre_diff = None)->np.ndarray:\n",
    "    \"\"\"Implemented Auto Regressive model\n",
    "\n",
    "    Args:\n",
    "        train (np.ndarray): Data used to estimating phi´s\n",
    "        time_steps (int): Number of steps to predict\n",
    "        model_order (int): Order p of model \n",
    "        pre_diff ([type], optional): Original data, if data has been differenced.Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Forecasted values \n",
    "    \"\"\"\n",
    "    #Yule Walker method to estimate phi´s\n",
    "    phi, _ = yule_walker(train, order = order)\n",
    "    \n",
    "    #create list for storing MSE-vals for all test days\n",
    "    mse_scores = np.zeros(len(test))\n",
    "    \n",
    "    # create matrix for storing all preds:\n",
    "    X_hat_matrix = np.zeros(shape=(len(test),(model_order + time_steps)))\n",
    "    #create empty array with lagged values and extra space for future preds(currently zeros)\n",
    "    \n",
    "    for count,day in enumerate(test):    \n",
    "        X_hat = np.zeros(model_order + time_steps)\n",
    "        X_hat[:order] = day\n",
    "        \n",
    "        \n",
    "        for step in range(time_steps):\n",
    "            X_t = 0\n",
    "            #Actual AR-model:\n",
    "            for p in range(model_order):\n",
    "                X_t += phi[p] * X_hat[(model_order+step)-(p+1)]\n",
    "            X_hat[model_order+step] = X_t\n",
    "\n",
    "        if pre_diff is not None:\n",
    "            #Add original inital value back and sum cumlative to undo differencing: \n",
    "            original_val = pre_diff[-order:]\n",
    "            X_hat[0] = original_val[0] + X_hat[0]\n",
    "            new_X_hat = X_hat.cumsum()\n",
    "            return new_X_hat\n",
    "        \n",
    "        \n",
    "        X_hat_matrix[count,:] = X_hat\n",
    "        mse_scores[count] = mean_squared_error(day, X_hat[:-time_steps])\n",
    "    \n",
    "    print(mse_scores.mean())\n",
    "    return X_hat_matrix\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "X_hat_matr = AR_model(train,test_days,time_steps,order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(X_hat)-time_steps), X_hat[-time_steps:], label = \"Forecast\")\n",
    "plt.plot(np.arange(len(test)), test, label = \"Actual\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1341f2ca8bae0273958fc68fc9062d4567e8214cb67a8c75fe7f4d8d8f4d5eac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('geo4300_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, History\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Bidirectional, TimeDistributed\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from common import *\n",
    "\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"rnn\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\", legend=True):\n",
    "    plt.plot(series, \".-\")\n",
    "    if y is not None:\n",
    "        plt.plot(n_steps, y, \"bo\", label=\"Target\")\n",
    "    if y_pred is not None:\n",
    "        plt.plot(n_steps, y_pred, \"rx\", markersize=10, label=\"Prediction\")\n",
    "    plt.grid(True)\n",
    "    if x_label:\n",
    "        plt.xlabel(x_label, fontsize=16)\n",
    "    if y_label:\n",
    "        plt.ylabel(y_label, fontsize=16, rotation=0)\n",
    "    plt.hlines(0, 0, 100, linewidth=1)\n",
    "    plt.axis([0, n_steps + 1, -1, 1])\n",
    "    plt.ylim(0,1)\n",
    "    if legend and (y or y_pred):\n",
    "        plt.legend(fontsize=14, loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_forecasts(X, Y, Y_pred):\n",
    "    n_steps = X.shape[1]\n",
    "    ahead = Y.shape[1]\n",
    "    plot_series(X[0, :, 0])\n",
    "    plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :, 0], \"bo-\", label=\"Actual\")\n",
    "    plt.plot(np.arange(n_steps, n_steps + ahead), Y_pred[0, :, 0], \"rx-\", label=\"Forecast\", markersize=10)\n",
    "    plt.ylim(0,1)\n",
    "    plt.axis([0, n_steps + ahead, -1, 1])\n",
    "    plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    #plt.axis([1, 20, 0, 0.05])\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series_data(raw_train_df, nbf_features, nbf_outputs, column_key, column_suffix=\"\", include_target_outputs=True):\n",
    "    nbf_columns = nbf_features + nbf_outputs\n",
    "    time_series_df, time_series = sliding_window_algorithm(raw_train_df, nbf_columns, nbf_features, nbf_outputs, column_key, column_suffix, include_target_outputs)\n",
    "    return time_series, time_series_df\n",
    "\n",
    "\n",
    "def sliding_window_algorithm(raw_data_df, nbf_columns, input_window, output_window, column_key, column_suffix, include_target_outputs, string_array=False):\n",
    "    raw_data = raw_data_df[column_key].to_numpy()\n",
    "    dim0 = raw_data.shape[0] - (nbf_columns - 1) # Number of time-slices\n",
    "    dim1 = nbf_columns # Time-step length including input window and output window\n",
    "    \n",
    "    if string_array:\n",
    "        data = np.empty((dim0,dim1), dtype=object) # Time series matrix\n",
    "    else:\n",
    "        data = np.zeros((dim0,dim1)) # Time series matrix\n",
    "\n",
    "    data[0, :] = raw_data[:dim1] # First initial sample/time-slice (n equals 0)\n",
    "    n = 1 # n is the count variable\n",
    "    \n",
    "    # Looping through the initial input data and constucting the \n",
    "    # time series data based on the sliding window approach. \n",
    "    # See the report for more descriptions\n",
    "    for j in range(dim1, raw_data.shape[0]):\n",
    "        data[n, :-1] = data[n-1, 1:]\n",
    "        data[n, nbf_columns-1:] = raw_data[j]\n",
    "        n += 1\n",
    "\n",
    "    if include_target_outputs:\n",
    "        # Creating dataframe    \n",
    "        feature_names = [f\"x{i}_{column_suffix}\" for i in range(1,input_window+1)]\n",
    "        if(output_window > 1):\n",
    "            output_names = [f\"y{i}_{column_suffix}\" for i in range(1,output_window+1)]    \n",
    "        else:\n",
    "            output_names = [f\"y_{column_suffix}\"]\n",
    "        \n",
    "        time_series_df = pd.DataFrame(data=data, columns=feature_names+output_names)\n",
    "    else:\n",
    "        feature_names = [f\"x{i}_{column_suffix}\" for i in range(1,input_window+2)]\n",
    "        time_series_df = pd.DataFrame(data=data, columns=feature_names)\n",
    "\n",
    "    return time_series_df, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series_data(raw_train_df, nbf_features, nbf_outputs, column_key, column_suffix=\"\", include_target_outputs=True):\n",
    "    nbf_columns = nbf_features + nbf_outputs\n",
    "    time_series_df, time_series = sliding_window_algorithm(raw_train_df, nbf_columns, nbf_features, nbf_outputs, column_key, column_suffix, include_target_outputs)\n",
    "    return time_series, time_series_df\n",
    "\n",
    "\n",
    "def sliding_window_algorithm(raw_data_df, nbf_columns, input_window, output_window, column_key, column_suffix, include_target_outputs, string_array=False):\n",
    "    raw_data = raw_data_df[column_key].to_numpy()\n",
    "    dim0 = raw_data.shape[0] - (nbf_columns - 1) # Number of time-slices\n",
    "    dim1 = nbf_columns # Time-step length including input window and output window\n",
    "    \n",
    "    if string_array:\n",
    "        data = np.empty((dim0,dim1), dtype=object) # Time series matrix\n",
    "    else:\n",
    "        data = np.zeros((dim0,dim1)) # Time series matrix\n",
    "\n",
    "    data[0, :] = raw_data[:dim1] # First initial sample/time-slice (n equals 0)\n",
    "    n = 1 # n is the count variable\n",
    "    \n",
    "    stride = 2\n",
    "    # Looping through the initial input data and constucting the \n",
    "    # time series data based on the sliding window approach. \n",
    "    # See the report for more descriptions\n",
    "    for j in range(dim1, raw_data.shape[0], stride):\n",
    "        data[n, :-1] = data[n-1, 1:]\n",
    "        data[n, nbf_columns-1:] = raw_data[j]\n",
    "        n += 1\n",
    "\n",
    "    if include_target_outputs:\n",
    "        # Creating dataframe    \n",
    "        feature_names = [f\"x{i}_{column_suffix}\" for i in range(1,input_window+1)]\n",
    "        if(output_window > 1):\n",
    "            output_names = [f\"y{i}_{column_suffix}\" for i in range(1,output_window+1)]    \n",
    "        else:\n",
    "            output_names = [f\"y_{column_suffix}\"]\n",
    "        \n",
    "        time_series_df = pd.DataFrame(data=data, columns=feature_names+output_names)\n",
    "    else:\n",
    "        feature_names = [f\"x{i}_{column_suffix}\" for i in range(1,input_window+2)]\n",
    "        time_series_df = pd.DataFrame(data=data, columns=feature_names)\n",
    "\n",
    "    return time_series_df, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44267, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO5_price</th>\n",
       "      <th>NO5_load_actual</th>\n",
       "      <th>NO5_load_delta</th>\n",
       "      <th>NO5_generation_actual</th>\n",
       "      <th>NO5_generation_delta</th>\n",
       "      <th>dato_id</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44264</th>\n",
       "      <td>35.69</td>\n",
       "      <td>2459</td>\n",
       "      <td>-241</td>\n",
       "      <td>8286</td>\n",
       "      <td>-4139</td>\n",
       "      <td>2021-01-20 20:00:00+01:00</td>\n",
       "      <td>2021-01-20-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44265</th>\n",
       "      <td>32.19</td>\n",
       "      <td>2385</td>\n",
       "      <td>-308</td>\n",
       "      <td>6884</td>\n",
       "      <td>-3499</td>\n",
       "      <td>2021-01-20 21:00:00+01:00</td>\n",
       "      <td>2021-01-20-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44266</th>\n",
       "      <td>29.49</td>\n",
       "      <td>2326</td>\n",
       "      <td>-360</td>\n",
       "      <td>5496</td>\n",
       "      <td>-2752</td>\n",
       "      <td>2021-01-20 22:00:00+01:00</td>\n",
       "      <td>2021-01-20-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NO5_price  NO5_load_actual  NO5_load_delta  NO5_generation_actual  \\\n",
       "44264      35.69             2459            -241                   8286   \n",
       "44265      32.19             2385            -308                   6884   \n",
       "44266      29.49             2326            -360                   5496   \n",
       "\n",
       "       NO5_generation_delta                    dato_id      date_time  \n",
       "44264                 -4139  2021-01-20 20:00:00+01:00  2021-01-20-20  \n",
       "44265                 -3499  2021-01-20 21:00:00+01:00  2021-01-20-21  \n",
       "44266                 -2752  2021-01-20 22:00:00+01:00  2021-01-20-22  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** (44267, 1)\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "dataset_df = pd.read_csv(f\"{INPUT_DATA}MAIN_DATASET.csv\")[[\"NO5_price\", \"NO5_load_actual\",\"NO5_load_delta\", \"NO5_generation_actual\", \"NO5_generation_delta\", \"dato_id\",\"date_time\"]][:-7381]; print(dataset_df.shape)\n",
    "\n",
    "display(dataset_df.tail(3))\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "print(\"***\",dataset_df[\"NO5_price\"].values.reshape(-1,1).shape)\n",
    "\n",
    "dataset_df[\"NO5_price\"] = scaler.fit_transform(dataset_df[\"NO5_price\"].values.reshape(-1,1))\n",
    "dataset_df[\"NO5_load_actual\"] = scaler.fit_transform(dataset_df[\"NO5_load_actual\"].values.reshape(-1,1))\n",
    "dataset_df[\"NO5_load_delta\"] = scaler.fit_transform(dataset_df[\"NO5_load_delta\"].values.reshape(-1,1))\n",
    "dataset_df[\"NO5_generation_actual\"] = scaler.fit_transform(dataset_df[\"NO5_generation_actual\"].values.reshape(-1,1))\n",
    "dataset_df[\"NO5_generation_delta\"] = scaler.fit_transform(dataset_df[\"NO5_generation_delta\"].values.reshape(-1,1))\n",
    "\n",
    "# Forecast solutions\n",
    "# training_df, forcast_sol_df = train_test_split(training_df, shuffle=False, test_size=0.2, random_state=4155)\n",
    "\n",
    "# Displaying the loaded data\n",
    "# display(training_df.tail(3))\n",
    "# print(training_df.shape)\n",
    "# display(forcast_sol_df.head(3))\n",
    "# print(forcast_sol_df.shape)\n",
    "\n",
    "# print(training_df.max())\n",
    "\n",
    "# print(training_df.min())\n",
    "# print(forcast_sol_df.max())\n",
    "# print(forcast_sol_df.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeqToVec\n",
    "Returning only the last output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44186, 82)\n",
      "(44186, 82)\n",
      "(34272, 72, 1) (34272, 10)\n",
      "(6581, 72, 1) (6581, 10)\n",
      "(3333, 72, 1) (3333, 10)\n"
     ]
    }
   ],
   "source": [
    "# Time series slicing parameters\n",
    "nbf_features = input_window = n_steps = 72 \n",
    "nbf_outputs = output_window = horizon = 10\n",
    "\n",
    "# Creating time series traing and evaluation (test) data besed on sliding window approach\n",
    "time_series, time_series_df = create_time_series_data(dataset_df,                                                                             \n",
    "                                                      nbf_features, \n",
    "                                                      nbf_outputs, \n",
    "                                                      column_key=\"NO5_price\", \n",
    "                                                      column_suffix=\"DA\",\n",
    "                                                      include_target_outputs=True)\n",
    "#time_series_df.to_csv(\"TIMESERIES_VALIDATION.csv\")\n",
    "\n",
    "\n",
    "# Displaying time series data\n",
    "time_series_df.index.name = \"t\"\n",
    "\n",
    "print(time_series.shape)\n",
    "print(time_series_df.shape)\n",
    "# print(time_series_df.columns)\n",
    "\n",
    "X_train, y_train = time_series[ :34272, :input_window], time_series[ :34272, input_window:]\n",
    "X_valid, y_valid = time_series[34272:34272+6581, :input_window], time_series[34272:34272+6581, input_window:]\n",
    "X_test, y_test = time_series[34272+6581:, :input_window], time_series[34272+6581:, input_window:]\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_valid = np.expand_dims(X_valid, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_DA</th>\n",
       "      <th>x2_DA</th>\n",
       "      <th>x3_DA</th>\n",
       "      <th>x4_DA</th>\n",
       "      <th>x5_DA</th>\n",
       "      <th>x6_DA</th>\n",
       "      <th>x7_DA</th>\n",
       "      <th>x8_DA</th>\n",
       "      <th>x9_DA</th>\n",
       "      <th>x10_DA</th>\n",
       "      <th>...</th>\n",
       "      <th>y1_DA</th>\n",
       "      <th>y2_DA</th>\n",
       "      <th>y3_DA</th>\n",
       "      <th>y4_DA</th>\n",
       "      <th>y5_DA</th>\n",
       "      <th>y6_DA</th>\n",
       "      <th>y7_DA</th>\n",
       "      <th>y8_DA</th>\n",
       "      <th>y9_DA</th>\n",
       "      <th>y10_DA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.157069</td>\n",
       "      <td>0.154630</td>\n",
       "      <td>0.154630</td>\n",
       "      <td>0.154108</td>\n",
       "      <td>0.162906</td>\n",
       "      <td>0.167262</td>\n",
       "      <td>0.165084</td>\n",
       "      <td>0.162035</td>\n",
       "      <td>0.158289</td>\n",
       "      <td>0.155153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326335</td>\n",
       "      <td>0.319714</td>\n",
       "      <td>0.259953</td>\n",
       "      <td>0.246189</td>\n",
       "      <td>0.246711</td>\n",
       "      <td>0.258646</td>\n",
       "      <td>0.246363</td>\n",
       "      <td>0.234864</td>\n",
       "      <td>0.217441</td>\n",
       "      <td>0.192961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.154630</td>\n",
       "      <td>0.154630</td>\n",
       "      <td>0.154108</td>\n",
       "      <td>0.162906</td>\n",
       "      <td>0.167262</td>\n",
       "      <td>0.165084</td>\n",
       "      <td>0.162035</td>\n",
       "      <td>0.158289</td>\n",
       "      <td>0.155153</td>\n",
       "      <td>0.149142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319714</td>\n",
       "      <td>0.259953</td>\n",
       "      <td>0.246189</td>\n",
       "      <td>0.246711</td>\n",
       "      <td>0.258646</td>\n",
       "      <td>0.246363</td>\n",
       "      <td>0.234864</td>\n",
       "      <td>0.217441</td>\n",
       "      <td>0.192961</td>\n",
       "      <td>0.179110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.154630</td>\n",
       "      <td>0.154108</td>\n",
       "      <td>0.162906</td>\n",
       "      <td>0.167262</td>\n",
       "      <td>0.165084</td>\n",
       "      <td>0.162035</td>\n",
       "      <td>0.158289</td>\n",
       "      <td>0.155153</td>\n",
       "      <td>0.149142</td>\n",
       "      <td>0.137904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259953</td>\n",
       "      <td>0.246189</td>\n",
       "      <td>0.246711</td>\n",
       "      <td>0.258646</td>\n",
       "      <td>0.246363</td>\n",
       "      <td>0.234864</td>\n",
       "      <td>0.217441</td>\n",
       "      <td>0.192961</td>\n",
       "      <td>0.179110</td>\n",
       "      <td>0.169527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.154108</td>\n",
       "      <td>0.162906</td>\n",
       "      <td>0.167262</td>\n",
       "      <td>0.165084</td>\n",
       "      <td>0.162035</td>\n",
       "      <td>0.158289</td>\n",
       "      <td>0.155153</td>\n",
       "      <td>0.149142</td>\n",
       "      <td>0.137904</td>\n",
       "      <td>0.139821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246189</td>\n",
       "      <td>0.246711</td>\n",
       "      <td>0.258646</td>\n",
       "      <td>0.246363</td>\n",
       "      <td>0.234864</td>\n",
       "      <td>0.217441</td>\n",
       "      <td>0.192961</td>\n",
       "      <td>0.179110</td>\n",
       "      <td>0.169527</td>\n",
       "      <td>0.191916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162906</td>\n",
       "      <td>0.167262</td>\n",
       "      <td>0.165084</td>\n",
       "      <td>0.162035</td>\n",
       "      <td>0.158289</td>\n",
       "      <td>0.155153</td>\n",
       "      <td>0.149142</td>\n",
       "      <td>0.137904</td>\n",
       "      <td>0.139821</td>\n",
       "      <td>0.138514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246711</td>\n",
       "      <td>0.258646</td>\n",
       "      <td>0.246363</td>\n",
       "      <td>0.234864</td>\n",
       "      <td>0.217441</td>\n",
       "      <td>0.192961</td>\n",
       "      <td>0.179110</td>\n",
       "      <td>0.169527</td>\n",
       "      <td>0.191916</td>\n",
       "      <td>0.190260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44181</th>\n",
       "      <td>0.416848</td>\n",
       "      <td>0.477742</td>\n",
       "      <td>0.506751</td>\n",
       "      <td>0.446729</td>\n",
       "      <td>0.460929</td>\n",
       "      <td>0.435926</td>\n",
       "      <td>0.466678</td>\n",
       "      <td>0.528705</td>\n",
       "      <td>0.584894</td>\n",
       "      <td>0.628016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339664</td>\n",
       "      <td>0.331910</td>\n",
       "      <td>0.331388</td>\n",
       "      <td>0.331126</td>\n",
       "      <td>0.321718</td>\n",
       "      <td>0.321369</td>\n",
       "      <td>0.331736</td>\n",
       "      <td>0.343410</td>\n",
       "      <td>0.397247</td>\n",
       "      <td>0.352818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44182</th>\n",
       "      <td>0.477742</td>\n",
       "      <td>0.506751</td>\n",
       "      <td>0.446729</td>\n",
       "      <td>0.460929</td>\n",
       "      <td>0.435926</td>\n",
       "      <td>0.466678</td>\n",
       "      <td>0.528705</td>\n",
       "      <td>0.584894</td>\n",
       "      <td>0.628016</td>\n",
       "      <td>0.558150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331910</td>\n",
       "      <td>0.331388</td>\n",
       "      <td>0.331126</td>\n",
       "      <td>0.321718</td>\n",
       "      <td>0.321369</td>\n",
       "      <td>0.331736</td>\n",
       "      <td>0.343410</td>\n",
       "      <td>0.397247</td>\n",
       "      <td>0.352818</td>\n",
       "      <td>0.341667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44183</th>\n",
       "      <td>0.506751</td>\n",
       "      <td>0.446729</td>\n",
       "      <td>0.460929</td>\n",
       "      <td>0.435926</td>\n",
       "      <td>0.466678</td>\n",
       "      <td>0.528705</td>\n",
       "      <td>0.584894</td>\n",
       "      <td>0.628016</td>\n",
       "      <td>0.558150</td>\n",
       "      <td>0.544821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331388</td>\n",
       "      <td>0.331126</td>\n",
       "      <td>0.321718</td>\n",
       "      <td>0.321369</td>\n",
       "      <td>0.331736</td>\n",
       "      <td>0.343410</td>\n",
       "      <td>0.397247</td>\n",
       "      <td>0.352818</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.311700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44184</th>\n",
       "      <td>0.446729</td>\n",
       "      <td>0.460929</td>\n",
       "      <td>0.435926</td>\n",
       "      <td>0.466678</td>\n",
       "      <td>0.528705</td>\n",
       "      <td>0.584894</td>\n",
       "      <td>0.628016</td>\n",
       "      <td>0.558150</td>\n",
       "      <td>0.544821</td>\n",
       "      <td>0.484798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331126</td>\n",
       "      <td>0.321718</td>\n",
       "      <td>0.321369</td>\n",
       "      <td>0.331736</td>\n",
       "      <td>0.343410</td>\n",
       "      <td>0.397247</td>\n",
       "      <td>0.352818</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.281209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44185</th>\n",
       "      <td>0.460929</td>\n",
       "      <td>0.435926</td>\n",
       "      <td>0.466678</td>\n",
       "      <td>0.528705</td>\n",
       "      <td>0.584894</td>\n",
       "      <td>0.628016</td>\n",
       "      <td>0.558150</td>\n",
       "      <td>0.544821</td>\n",
       "      <td>0.484798</td>\n",
       "      <td>0.454918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321718</td>\n",
       "      <td>0.321369</td>\n",
       "      <td>0.331736</td>\n",
       "      <td>0.343410</td>\n",
       "      <td>0.397247</td>\n",
       "      <td>0.352818</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.281209</td>\n",
       "      <td>0.257688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44186 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1_DA     x2_DA     x3_DA     x4_DA     x5_DA     x6_DA     x7_DA  \\\n",
       "t                                                                             \n",
       "0      0.157069  0.154630  0.154630  0.154108  0.162906  0.167262  0.165084   \n",
       "1      0.154630  0.154630  0.154108  0.162906  0.167262  0.165084  0.162035   \n",
       "2      0.154630  0.154108  0.162906  0.167262  0.165084  0.162035  0.158289   \n",
       "3      0.154108  0.162906  0.167262  0.165084  0.162035  0.158289  0.155153   \n",
       "4      0.162906  0.167262  0.165084  0.162035  0.158289  0.155153  0.149142   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "44181  0.416848  0.477742  0.506751  0.446729  0.460929  0.435926  0.466678   \n",
       "44182  0.477742  0.506751  0.446729  0.460929  0.435926  0.466678  0.528705   \n",
       "44183  0.506751  0.446729  0.460929  0.435926  0.466678  0.528705  0.584894   \n",
       "44184  0.446729  0.460929  0.435926  0.466678  0.528705  0.584894  0.628016   \n",
       "44185  0.460929  0.435926  0.466678  0.528705  0.584894  0.628016  0.558150   \n",
       "\n",
       "          x8_DA     x9_DA    x10_DA  ...     y1_DA     y2_DA     y3_DA  \\\n",
       "t                                    ...                                 \n",
       "0      0.162035  0.158289  0.155153  ...  0.326335  0.319714  0.259953   \n",
       "1      0.158289  0.155153  0.149142  ...  0.319714  0.259953  0.246189   \n",
       "2      0.155153  0.149142  0.137904  ...  0.259953  0.246189  0.246711   \n",
       "3      0.149142  0.137904  0.139821  ...  0.246189  0.246711  0.258646   \n",
       "4      0.137904  0.139821  0.138514  ...  0.246711  0.258646  0.246363   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "44181  0.528705  0.584894  0.628016  ...  0.339664  0.331910  0.331388   \n",
       "44182  0.584894  0.628016  0.558150  ...  0.331910  0.331388  0.331126   \n",
       "44183  0.628016  0.558150  0.544821  ...  0.331388  0.331126  0.321718   \n",
       "44184  0.558150  0.544821  0.484798  ...  0.331126  0.321718  0.321369   \n",
       "44185  0.544821  0.484798  0.454918  ...  0.321718  0.321369  0.331736   \n",
       "\n",
       "          y4_DA     y5_DA     y6_DA     y7_DA     y8_DA     y9_DA    y10_DA  \n",
       "t                                                                            \n",
       "0      0.246189  0.246711  0.258646  0.246363  0.234864  0.217441  0.192961  \n",
       "1      0.246711  0.258646  0.246363  0.234864  0.217441  0.192961  0.179110  \n",
       "2      0.258646  0.246363  0.234864  0.217441  0.192961  0.179110  0.169527  \n",
       "3      0.246363  0.234864  0.217441  0.192961  0.179110  0.169527  0.191916  \n",
       "4      0.234864  0.217441  0.192961  0.179110  0.169527  0.191916  0.190260  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "44181  0.331126  0.321718  0.321369  0.331736  0.343410  0.397247  0.352818  \n",
       "44182  0.321718  0.321369  0.331736  0.343410  0.397247  0.352818  0.341667  \n",
       "44183  0.321369  0.331736  0.343410  0.397247  0.352818  0.341667  0.311700  \n",
       "44184  0.331736  0.343410  0.397247  0.352818  0.341667  0.311700  0.281209  \n",
       "44185  0.343410  0.397247  0.352818  0.341667  0.311700  0.281209  0.257688  \n",
       "\n",
       "[44186 rows x 82 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(time_series_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{X_train.shape=}\")\n",
    "print(f\"{y_train.shape=}\")\n",
    "print(f\"{X_valid.shape=}\")\n",
    "print(f\"{y_valid.shape=}\")\n",
    "\n",
    "eta = 0.002\n",
    "batch_size = 200\n",
    "epochs =20\n",
    "model = keras.models.Sequential([\n",
    "    LSTM(25, return_sequences=True, input_shape=[None, 72]),\n",
    "    LSTM(25, return_sequences=True),\n",
    "    TimeDistributed(keras.layers.Dense(1))\n",
    "])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.000001)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=eta)\n",
    "model.compile(loss=\"mse\", optimizer=opt)\n",
    "\n",
    "callbacks = [learning_rate_reduction]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "history = model.fit(np.swapaxes(X_train, 1, 2), y_train, \n",
    "                    epochs=20, shuffle=False, \n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(np.swapaxes(X_valid, 1, 2), y_valid),\n",
    "                    callbacks= callbacks)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(np.swapaxes(X_valid, 1,2), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.swapaxes(X_valid, 1,2))\n",
    "plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtbelVxDOq63"
   },
   "source": [
    "## Forecasting Several Steps Ahead\n",
    "Iterative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series slicing parameters\n",
    "nbf_features = input_window = n_steps = 72 \n",
    "nbf_outputs = output_window = horizon = 24\n",
    "\n",
    "# Creating time series traing and evaluation (test) data besed on sliding window approach\n",
    "time_series, time_series_df = create_time_series_data(dataset_df,                                                                             \n",
    "                                                      nbf_features, \n",
    "                                                      nbf_outputs, \n",
    "                                                      column_key=\"NO5_price\", \n",
    "                                                      column_suffix=\"DA\",\n",
    "                                                      include_target_outputs=True)\n",
    "#time_series_df.to_csv(\"TIMESERIES_VALIDATION.csv\")\n",
    "\n",
    "\n",
    "# Displaying time series data\n",
    "time_series_df.index.name = \"t\"\n",
    "\n",
    "print(time_series.shape)\n",
    "print(time_series_df.shape)\n",
    "# print(time_series_df.columns)\n",
    "\n",
    "X_train, y_train = time_series[ :34272, :input_window], time_series[ :34272, input_window:]\n",
    "X_valid, y_valid = time_series[34272:34272+6581, :input_window], time_series[34272:34272+6581, input_window:]\n",
    "X_test, y_test = time_series[34272+6581:, :input_window], time_series[34272+6581:, input_window:]\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_valid = np.expand_dims(X_valid, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43) # not 42, as it would give the first series in the train set\n",
    "\n",
    "X_new = X_test[-1:, :]\n",
    "Y_new = np.expand_dims(y_test[-1:, :], 2)\n",
    "\n",
    "display(dataset_df[[\"NO5_price\", \"date_time\"]].tail(1))\n",
    "\n",
    "print(f\"{X_new.shape=}\")\n",
    "print(f\"{Y_new.shape=}\")\n",
    "\n",
    "# X = X_new\n",
    "X = np.swapaxes(X_new, 1,2)\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "for step_ahead in range(horizon):\n",
    "    # y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    y_pred_one = model.predict(X[:, :, step_ahead:])\n",
    "\n",
    "    print(f\"{y_pred_one.shape=}\")\n",
    "    #y_pred_one = y_pred_one[:, np.newaxis, :]\n",
    "\n",
    "    # X = np.concatenate([X, y_pred_one], axis=1)\n",
    "    print(f\"{y_pred_one.shape=}\")\n",
    "\n",
    "    X = np.concatenate([X, y_pred_one], axis=2)\n",
    "    print(f\"{X.shape=}\")\n",
    "\n",
    "print(f\"{X.shape=}\")\n",
    "Y_pred = X[:, n_steps:]\n",
    "Y_pred = X[:,:, n_steps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.swapaxes(Y_pred, 1,2)\n",
    "print(Y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_forecasts(X_new, Y_new, Y_pred)\n",
    "save_fig(\"forecast_ahead_plot\")\n",
    "plt.ylim(0.10,0.70)\n",
    "plt.show()\n",
    "\n",
    "mse = keras.metrics.mean_squared_error(Y_new, Y_pred)\n",
    "print(\"MSE:\",np.mean(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series slicing parameters\n",
    "nbf_features = input_window = n_steps = 72 \n",
    "nbf_outputs = output_window = 24\n",
    "\n",
    "\n",
    "# Creating time series traing and evaluation (test) data besed on sliding window approach\n",
    "time_series, time_series_df = create_time_series_data(dataset_df,                                                                             \n",
    "                                                      nbf_features, \n",
    "                                                      nbf_outputs, \n",
    "                                                      column_key=\"NO5_price\", \n",
    "                                                      column_suffix=\"DA\",\n",
    "                                                      include_target_outputs=True)\n",
    "#time_series_df.to_csv(\"TIMESERIES_VALIDATION.csv\")\n",
    "\n",
    "\n",
    "# Displaying time series data\n",
    "time_series_df.index.name = \"t\"\n",
    "\n",
    "print(time_series.shape)\n",
    "print(time_series_df.shape)\n",
    "# print(time_series_df.columns)\n",
    "\n",
    "X_train, y_train = time_series[ :34272, :input_window], time_series[ :34272, input_window:]\n",
    "X_valid, y_valid = time_series[34272:34272+6581, :input_window], time_series[34272:34272+6581, input_window:]\n",
    "X_test, y_test = time_series[34272+6581:, :input_window], time_series[34272+6581:, input_window:]\n",
    "\n",
    "# X_train = np.expand_dims(X_train, axis=2)\n",
    "# X_valid = np.expand_dims(X_valid, axis=2)\n",
    "# X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLR_model = LinearRegression()\n",
    "MLR_model.fit(X_train, y_train[:, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_new = X_test[-1:, :]\n",
    "Y_new = y_test[-1:, :]\n",
    "\n",
    "X = X_new\n",
    "\n",
    "\n",
    "for step_ahead in range(24):\n",
    "    # y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    y_pred_one = MLR_model.predict(X[:, step_ahead:])\n",
    "\n",
    "    print(y_pred_one)\n",
    "\n",
    "    print(f\"{y_pred_one.shape=}\")\n",
    "    #y_pred_one = y_pred_one[:, np.newaxis, :]\n",
    "\n",
    "    # X = np.concatenate([X, y_pred_one], axis=1)\n",
    "    print(f\"{y_pred_one.shape=}\")\n",
    "\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "    print(f\"{X.shape=}\")\n",
    "\n",
    "print(f\"{X.shape=}\")\n",
    "Y_pred = X[:, n_steps:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.expand_dims(X_new,2)\n",
    "Y_new = np.expand_dims(Y_new,2)\n",
    "Y_pred = np.expand_dims(Y_pred,2)\n",
    "\n",
    "plot_multiple_forecasts(X_new, Y_new, Y_pred)\n",
    "save_fig(\"forecast_ahead_plot\")\n",
    "plt.ylim(0.10,0.70)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mse = keras.metrics.mean_squared_error(Y_new, Y_pred)\n",
    "print(\"MSE:\",np.mean(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_project2 import *\n",
    "eta = 0.05\n",
    "lmb = 0\n",
    "hidden_size = 64\n",
    "act_func = \"relu\"\n",
    "act_func = \"leaky_relu\"\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_model, tf_model = NN_simple_architecture(eta, nbf_features,\n",
    "                                                         problem_type=\"regression\",\n",
    "                                                         nbf_outputs=1,\n",
    "                                                         X_test=X_test.copy(), t_test=y_test.copy()[:, :1],\n",
    "                                                         lmb=lmb, \n",
    "                                                         hidden_size=hidden_size, \n",
    "                                                         act_func=act_func)\n",
    "\n",
    "own_model, tf_model = NN_large_architecture(eta, nbf_features,\n",
    "                                                         problem_type=\"regression\",\n",
    "                                                         nbf_outputs=1,\n",
    "                                                         X_test=X_test.copy(), t_test=y_test.copy()[:, :1],\n",
    "                                                         lmb=lmb, \n",
    "                                                         hidden_size=hidden_size, \n",
    "                                                         act_func=act_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train[:, :1])\n",
    "\n",
    "train_losses, test_losses = own_model.fit(X_train, y_train[:, :1], \n",
    "                                                            batch_size=batch_size, epochs=epochs,\n",
    "                                                            lr_scheduler=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x_plot = np.arange(train_losses.shape[0])\n",
    "plt.plot(x_plot, train_losses)\n",
    "plt.plot(x_plot, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_hat_test_own = own_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(43) # not 42, as it would give the first series in the train set\n",
    "\n",
    "X_new = X_test[-1:, :]\n",
    "Y_new = y_test[-1:, :]\n",
    "\n",
    "X = X_new\n",
    "\n",
    "\n",
    "for step_ahead in range(24):\n",
    "    # y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    y_pred_one = own_model.predict(X[:, step_ahead:])\n",
    "\n",
    "    print(y_pred_one)\n",
    "\n",
    "    print(f\"{y_pred_one.shape=}\")\n",
    "    #y_pred_one = y_pred_one[:, np.newaxis, :]\n",
    "\n",
    "    # X = np.concatenate([X, y_pred_one], axis=1)\n",
    "    print(f\"{y_pred_one.shape=}\")\n",
    "\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "    print(f\"{X.shape=}\")\n",
    "\n",
    "print(f\"{X.shape=}\")\n",
    "Y_pred = X[:, n_steps:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.expand_dims(X_new,2)\n",
    "Y_new = np.expand_dims(Y_new,2)\n",
    "Y_pred = np.expand_dims(Y_pred,2)\n",
    "print(f\"{Y_pred.shape=}\")\n",
    "print(f\"{Y_new.shape=}\")\n",
    "print(f\"{X_new.shape=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_forecasts(X_new, Y_new, Y_pred)\n",
    "save_fig(\"forecast_ahead_plot\")\n",
    "plt.ylim(0.10,0.70)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "mse = keras.metrics.mean_squared_error(Y_new, Y_pred)\n",
    "print(\"MSE:\",np.mean(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "664767e83c7b06364e16bf4bb7694b1f8b5947c6e3e0843db3deeed47f8be06a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('fysstk1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

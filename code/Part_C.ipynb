{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "from common import *\n",
    "from models import *\n",
    "import tensorflow as tf\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from matplotlib import cm as matplot_cm\n",
    "\n",
    "print(tf. __version__) \n",
    "# print('tensorflow version', tf.__version__)\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "print(f\"Root directory: {os.getcwd()}\")\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "    \"font.size\": 10,\n",
    "})\n",
    "\n",
    "#%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# filename = f\"best_model.pkl\"\n",
    "# save_model(model, filename)\n",
    "# load_model(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_VALUE = 70707070\n",
    "np.random.seed(SEED_VALUE)\n",
    "SAVE_FIGURES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data and resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the terrain\n",
    "terrain1_file = \"SRTM_data_Norway_1.tif\"\n",
    "terrain2_file = \"SRTM_data_Norway_2.tif\"\n",
    "terrain1 =  imread(f'{INPUT_DATA}{terrain1_file}')\n",
    "terrain2 = imread(f'{INPUT_DATA}{terrain2_file}')\n",
    "\n",
    "# Resizing the image\n",
    "rescale_factor = 0.1\n",
    "y_size = int(terrain1.shape[0] * rescale_factor)\n",
    "x_size = int(terrain1.shape[1] * rescale_factor)\n",
    "terrain1Resized = cv2.resize(terrain1, (x_size, y_size))\n",
    "terrain2Resized = cv2.resize(terrain2, (x_size, y_size))\n",
    "\n",
    "# Plotting terrain\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.title.set_text(\"Terrain over Norway 1 (Resized)\")\n",
    "ax1.set_xlabel(\"X\"); ax1.set_ylabel(\"Y\")\n",
    "surf1 = ax1.imshow(terrain1Resized, cmap='gray')\n",
    "ax2.title.set_text(\"Terrain over Norway 2 (Resized)\")\n",
    "ax2.set_xlabel(\"X\"); ax2.set_ylabel(\"Y\")\n",
    "surf2 = ax2.imshow(terrain2Resized, cmap='gray')\n",
    "\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(f\"{REPORT_FIGURES}{EX_A}terrain_data_resized.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating image patches and Terrain data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nXpatches = 3; nYpatches=6\n",
    "y_steps = int(terrain2Resized.shape[0] / nYpatches); print(y_steps)\n",
    "x_steps = int(terrain2Resized.shape[1] / nXpatches); print(x_steps)\n",
    "\n",
    "patches_1 = create_img_patches(terrain1Resized, y_steps, x_steps)\n",
    "if SAVE_FIGURES:\n",
    "    fig1 = plotTerrainPatches(patches_1, nYpatches, nXpatches, plotTitle=\"Terrain1 patches\")\n",
    "    plt.savefig(f\"{REPORT_FIGURES}{EX_A}Terrain1_patches.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "patches_2 = create_img_patches(terrain2Resized, y_steps, x_steps)\n",
    "if SAVE_FIGURES:\n",
    "    fig2 = plotTerrainPatches(patches_2, nYpatches, nXpatches, plotTitle=\"Terrain2 patches\")\n",
    "    plt.savefig(f\"{REPORT_FIGURES}{EX_A}Terrain2_patches.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "# Choosing two interesting terrain patches\n",
    "img1 = patches_1[2]\n",
    "img2 = patches_2[5]\n",
    "x1, y1, z1 = createTerrainData(img1)\n",
    "x2, y2, z2 = createTerrainData(img2)\n",
    "\n",
    "# Constructing the terrain data\n",
    "terrain_data = 1\n",
    "if terrain_data == 1: # Choosing terrain1*\n",
    "    x, y, z = x1, y1, z1.copy() \n",
    "    #z_min = np.min(z)\n",
    "    z_max = np.max(z)\n",
    "    z = z1\n",
    "\n",
    "elif terrain_data == 2: # Choosing terrain2\n",
    "    x, y, z = x2, y2, z2.copy() \n",
    "    #z_min = np.min(z)\n",
    "    z_max = np.max(z)\n",
    "    z = z2\n",
    "    \n",
    "z_flat = z.ravel(); \n",
    "z_flat = z_flat.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ploting of best model and its prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"../data/models/the_very_best_model/\"\n",
    "filename = f\"{path}best_large_model_leaky_relu_mse_0.108.pkl\"\n",
    "best_model = load_model(filename)\n",
    "\n",
    "deg = 1\n",
    "X = create_X(x, y, deg) # Design Matrix \n",
    "X = remove_intercept(X)\n",
    "X_scaled, _ = standard_scaling_single(X)\n",
    "z_scaled, z_scaler = standard_scaling_single(z.ravel().reshape(-1,1))\n",
    "\n",
    "\n",
    "z_hat = best_model.predict(X_scaled)\n",
    "z_hat = z_scaler.inverse_transform(z_hat.reshape(-1,1))\n",
    "z_hat = z_hat.reshape((y_steps,x_steps))\n",
    "mean_val = np.round(np.mean(z_hat),decimals=1)\n",
    "var_val = np.round(np.var(z_hat),decimals=1)\n",
    "\n",
    "\n",
    "# 2D plot of target terrain \n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(z ,cmap='rainbow')\n",
    "title = f\"Target terrain\\nOwn Neural Net\\nMean: {np.round(np.mean(z), decimals=1)}\\nVariance: {np.round(np.mean(z),decimals=1)}\"\n",
    "plt.title(title)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.savefig(f\"{path}2d_plot_target.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2D plot of predicted terrain \n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(z_hat ,cmap='rainbow')\n",
    "title = f\"Predicted terrain\\nOwn Neural Net\\nMean: {mean_val}\\nVariance: {var_val}\"\n",
    "plt.title(title)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.savefig(f\"{path}2d_plot_predicted.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 3D plot of target terrain\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "title = f\"Target terrain\\nOwn Neural Net\"\n",
    "ax.title.set_text(title)\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\n",
    "#ax2.view_init(elev=60., azim=-120.0-70)\n",
    "ax.view_init(elev=-75., azim=-91)\n",
    "# sutf = ax.plot_surface(x, y, z_hat, cmap=matplot_cm.coolwarm, linewidth = 0, antialiased=False)\n",
    "sutf = ax.plot_surface(x, y, z, cmap=\"rainbow\", linewidth = 0, antialiased=False)\n",
    "plt.savefig(f\"{path}3d_plot-target.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# 3D plot of predicted terrain\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "title = f\"Predicted terrain\\nOwn Neural Net\"\n",
    "ax.title.set_text(title)\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\n",
    "#ax2.view_init(elev=60., azim=-120.0-70)\n",
    "ax.view_init(elev=-75., azim=-91)\n",
    "# sutf = ax.plot_surface(x, y, z_hat, cmap=matplot_cm.coolwarm, linewidth = 0, antialiased=False)\n",
    "sutf = ax.plot_surface(x, y, z_hat, cmap=\"rainbow\", linewidth = 0, antialiased=False)\n",
    "plt.savefig(f\"{path}3d_plot-predicted.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Terrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4155)\n",
    "\n",
    "degree = 1\n",
    "X = create_X(x,y, degree)\n",
    "X = X[:,1:]\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, z_flat, test_size=0.2, shuffle=True)\n",
    "\n",
    "X_train, X_test = standard_scaling(X_train, X_test)\n",
    "t_train, t_test = standard_scaling(t_train, t_test)\n",
    "\n",
    "lr_upper_limit = learning_rate_upper_limit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 300\n",
    "nbf_features = X_train.shape[1]\n",
    "apply_lr_scheduler = False\n",
    "hidden_sizes = np.array([32,16,8])\n",
    "eta_list = np.logspace(-1, -4, 6)\n",
    "lmb_list = np.concatenate([np.zeros(1).astype(float), np.logspace(-5, -3, 5)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search  - RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_func = \"relu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_mtrx_MSE = np.zeros(shape=(hidden_sizes.shape[0], eta_list.shape[0], lmb_list.shape[0]))\n",
    "heatmap_mtrx_MSE_tf = np.zeros_like(heatmap_mtrx_MSE)\n",
    "\n",
    "parameters_best_MSE = {\"best_MSE\" : np.Inf, \"R2_at_best_MSE\" : np.Inf ,\"parameters\":0,\n",
    "                      \"neurons_first_hidden\":0, \"learning_rate\":0, \"lambda\":0, \"epochs\": epochs, \"batch_size\":batch_size}\n",
    "parameters_best_MSE_tf = {\"best_MSE\" : np.Inf, \"R2_at_best_MSE\" : np.Inf , \"parameters\":0,\n",
    "                          \"neurons_first_hidden\":0, \"learning_rate\":0, \"lambda\":0, \"epochs\": epochs, \"batch_size\":batch_size}\n",
    "best_models = {\"own_NN\":None, \"tf_NN\":None}\n",
    "\n",
    "results_simple_df = pd.DataFrame(columns=[\"MSE_tensorflow\",\"R2_tensorflow\",\"MSE_own_NN\",\"R2_own_NN\",\n",
    "                                          \"parameters_own_NN\",\"neurons_first_hidden\",\"learning_rate\",\n",
    "                                          \"regularization\"])\n",
    "# Grid search on eta and lambda \n",
    "i = 0\n",
    "for n, hidden_size in tqdm(enumerate(hidden_sizes)):\n",
    "    for y, lmb in enumerate(lmb_list):\n",
    "        for x, eta in enumerate(eta_list):\n",
    "            np.random.seed(4155)\n",
    "            own_model, tf_model = NN_simple_architecture(eta, nbf_features,\n",
    "                                                         problem_type=\"regression\",\n",
    "                                                         X_test=X_test.copy(), t_test=t_test.copy(),\n",
    "                                                         lmb=lmb, \n",
    "                                                         hidden_size=hidden_size, \n",
    "                                                         act_func=act_func)\n",
    "            \n",
    "            print(f\"Neurons in first hidden: {hidden_size} - Parameters: {own_model.nbf_parameters} - Lambda: {lmb} -Eta: {eta}\")\n",
    "            # Own model\n",
    "            train_losses, test_losses = own_model.fit(X_train.copy(), t_train.copy(), \n",
    "                                                            batch_size=batch_size, epochs=epochs,\n",
    "                                                            lr_scheduler=apply_lr_scheduler, verbose=False)\n",
    "            t_hat_test_own = own_model.predict(X_test.copy())\n",
    "            \n",
    "            MSE_val = np.around(MSE(t_test, t_hat_test_own), decimals=4)\n",
    "            R2_val = np.around(R2(t_test, t_hat_test_own), decimals=4)\n",
    "            heatmap_mtrx_MSE[n,y,x] = MSE_val\n",
    "\n",
    "            if parameters_best_MSE[\"best_MSE\"] > MSE_val:\n",
    "                print(f\"**New best MSE own NN**: {MSE_val}\")\n",
    "                best_models[\"own_NN\"] = own_model\n",
    "                parameters_best_MSE[\"best_MSE\"] = MSE_val\n",
    "                parameters_best_MSE[\"R2_at_best_MSE\"] = R2_val\n",
    "                parameters_best_MSE[\"parameters\"] = own_model.nbf_parameters\n",
    "                parameters_best_MSE[\"neurons_first_hidden\"] = hidden_size\n",
    "                parameters_best_MSE[\"learning_rate\"] = eta\n",
    "                parameters_best_MSE[\"lambda\"] = lmb\n",
    "                df = pd.DataFrame().from_dict(parameters_best_MSE, orient='index')\n",
    "                df.to_csv(f\"{REPORT_DATA}{EX_C}own_NN_best_training_small_{act_func}.csv\")\n",
    "                \n",
    "                plt.figure()\n",
    "                plt.plot(np.arange(epochs), train_losses, label=\"Train loss\")\n",
    "                plt.plot(np.arange(epochs), test_losses, label=\"Test loss\")\n",
    "                plt.title(f\"Best model own NN\\nMSE: {MSE_val}\\nNumber of parameters: {own_model.nbf_parameters}\\nLearning rate: {eta}\\nL2 Regularization: {lmb}\\n{act_func}\")\n",
    "                plt.xlabel(\"Epochs\")\n",
    "                plt.ylabel(\"Loss\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{REPORT_FIGURES}{EX_C}own_NN_best_training_small_{act_func}_lr_{eta}.pdf\")\n",
    "            \n",
    "                filename = f\"../data/models/best_small_model_{act_func}_mse_{np.around(MSE_val, decimals=4)}.pkl\"\n",
    "                save_model(own_model, filename)\n",
    "                        \n",
    "            # Tensorflow\n",
    "            tf_model.fit(X_train.copy(), t_train.copy(), batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "            t_hat_test_tf = tf_model.predict(X_test.copy())\n",
    "            \n",
    "            MSE_val_tf = np.around(MSE(t_test, t_hat_test_tf), decimals=4)\n",
    "            heatmap_mtrx_MSE_tf[n, y,x] = MSE_val_tf\n",
    "\n",
    "            if parameters_best_MSE_tf[\"best_MSE\"] > MSE_val_tf:\n",
    "                print(f\"New best MSE tensorflow: {MSE_val_tf}\")\n",
    "                parameters_best_MSE_tf[\"best_MSE\"] = MSE_val_tf\n",
    "                parameters_best_MSE_tf[\"parameters\"] = own_model.nbf_parameters\n",
    "                parameters_best_MSE_tf[\"neurons_first_hidden\"] = hidden_size\n",
    "                parameters_best_MSE_tf[\"learning_rate\"] = eta\n",
    "                parameters_best_MSE_tf[\"lambda\"] = lmb\n",
    "                best_models[\"tf_NN\"] = tf_model\n",
    "            \n",
    "            R2_val_tf = np.around(R2(t_test, t_hat_test_tf), decimals=4)\n",
    "            \n",
    "            \n",
    "            results_simple_df.loc[i] = [MSE_val_tf, R2_val_tf, MSE_val, R2_val, \n",
    "                                        own_model.nbf_parameters, hidden_size, eta, lmb]\n",
    "            results_simple_df.to_csv(f\"{REPORT_DATA}{EX_C}results_small_{act_func}.csv\")\n",
    "            i+=1\n",
    "            \n",
    "    plot_save_NN_results(parameters=own_model.nbf_parameters, model_size=\"small\", eta_list=eta_list, lmb_list=lmb_list, \n",
    "                         heatmap_mtrx=heatmap_mtrx_MSE[n, :,:], heatmap_mtrx_tf=heatmap_mtrx_MSE_tf[n, :,:],\n",
    "                         path=f\"{REPORT_FIGURES}{EX_C}\", activation_type=act_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_mtrx_MSE = np.zeros(shape=(hidden_sizes.shape[0], eta_list.shape[0], lmb_list.shape[0]))\n",
    "heatmap_mtrx_MSE_tf = np.zeros_like(heatmap_mtrx_MSE)\n",
    "\n",
    "parameters_best_MSE = {\"best_MSE\" : np.Inf, \"R2_at_best_MSE\" : np.Inf ,\"parameters\":0,\n",
    "                      \"neurons_first_hidden\":0, \"learning_rate\":0, \"lambda\":0, \"epochs\": epochs, \"batch_size\":batch_size}\n",
    "parameters_best_MSE_tf = {\"best_MSE\" : np.Inf, \"R2_at_best_MSE\" : np.Inf , \"parameters\":0,\n",
    "                          \"neurons_first_hidden\":0, \"learning_rate\":0, \"lambda\":0, \"epochs\": epochs, \"batch_size\":batch_size}\n",
    "best_models = {\"own_NN\":None, \"tf_NN\":None}\n",
    "\n",
    "results_large_df = pd.DataFrame(columns=[\"MSE_tensorflow\",\"R2_tensorflow\",\"MSE_own_NN\",\"R2_own_NN\",\n",
    "                                          \"parameters_own_NN\",\"neurons_first_hidden\",\"learning_rate\",\n",
    "                                          \"regularization\"])\n",
    "# Grid search on eta and lambda \n",
    "i = 0\n",
    "for n, hidden_size in tqdm(enumerate(hidden_sizes)):\n",
    "    for y, lmb in enumerate(lmb_list):\n",
    "        for x, eta in enumerate(eta_list):\n",
    "            np.random.seed(4155)\n",
    "            own_model, tf_model = NN_large_architecture(eta, nbf_features,\n",
    "                                                         problem_type=\"regression\",\n",
    "                                                         X_test=X_test.copy(), t_test=t_test.copy(),\n",
    "                                                         lmb=lmb, \n",
    "                                                         hidden_size=hidden_size, \n",
    "                                                         act_func=act_func)\n",
    "            \n",
    "            print(f\"Neurons in first hidden: {hidden_size} - Parameters: {own_model.nbf_parameters} - Lambda: {lmb} -Eta: {eta}\")\n",
    "            # Own model\n",
    "            train_losses, test_losses = own_model.fit(X_train.copy(), t_train.copy(), \n",
    "                                                            batch_size=batch_size, epochs=epochs,\n",
    "                                                            lr_scheduler=apply_lr_scheduler, verbose=False)\n",
    "            t_hat_test_own = own_model.predict(X_test.copy())\n",
    "            \n",
    "            MSE_val = np.around(MSE(t_test, t_hat_test_own), decimals=4)\n",
    "            R2_val = np.around(R2(t_test, t_hat_test_own), decimals=4)\n",
    "            heatmap_mtrx_MSE[n,y,x] = MSE_val\n",
    "\n",
    "            if parameters_best_MSE[\"best_MSE\"] > MSE_val:\n",
    "                print(f\"**New best MSE own NN**: {MSE_val}\")\n",
    "                best_models[\"own_NN\"] = own_model\n",
    "                parameters_best_MSE[\"best_MSE\"] = MSE_val\n",
    "                parameters_best_MSE[\"R2_at_best_MSE\"] = R2_val\n",
    "                parameters_best_MSE[\"parameters\"] = own_model.nbf_parameters\n",
    "                parameters_best_MSE[\"neurons_first_hidden\"] = hidden_size\n",
    "                parameters_best_MSE[\"learning_rate\"] = eta\n",
    "                parameters_best_MSE[\"lambda\"] = lmb\n",
    "                df = pd.DataFrame().from_dict(parameters_best_MSE, orient='index')\n",
    "                df.to_csv(f\"{REPORT_DATA}{EX_C}own_NN_best_training_large_{act_func}.csv\")\n",
    "                \n",
    "                plt.figure()\n",
    "                plt.plot(np.arange(epochs), train_losses, label=\"Train loss\")\n",
    "                plt.plot(np.arange(epochs), test_losses, label=\"Test loss\")\n",
    "                plt.title(f\"Best model own NN\\nMSE: {MSE_val}\\nNumber of parameters: {own_model.nbf_parameters}\\nLearning rate: {eta}\\nL2 Regularization: {lmb}\\n{act_func}\")\n",
    "                plt.xlabel(\"Epochs\")\n",
    "                plt.ylabel(\"Loss\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{REPORT_FIGURES}{EX_C}own_NN_best_training_large_{act_func}_lr_{eta}.pdf\")\n",
    "\n",
    "                filename = f\"../data/models/best_large_model_{act_func}_mse_{np.around(MSE_val, decimals=4)}.pkl\"\n",
    "                save_model(own_model, filename)\n",
    "                        \n",
    "            # Tensorflow\n",
    "            tf_model.fit(X_train.copy(), t_train.copy(), batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "            t_hat_test_tf = tf_model.predict(X_test.copy())\n",
    "            \n",
    "            MSE_val_tf = np.around(MSE(t_test, t_hat_test_tf), decimals=4)\n",
    "            heatmap_mtrx_MSE_tf[n, y,x] = MSE_val_tf\n",
    "\n",
    "            if parameters_best_MSE_tf[\"best_MSE\"] > MSE_val_tf:\n",
    "                print(f\"New best MSE tensorflow: {MSE_val_tf}\")\n",
    "                parameters_best_MSE_tf[\"best_MSE\"] = MSE_val_tf\n",
    "                parameters_best_MSE_tf[\"parameters\"] = own_model.nbf_parameters\n",
    "                parameters_best_MSE_tf[\"neurons_first_hidden\"] = hidden_size\n",
    "                parameters_best_MSE_tf[\"learning_rate\"] = eta\n",
    "                parameters_best_MSE_tf[\"lambda\"] = lmb\n",
    "                best_models[\"tf_NN\"] = tf_model\n",
    "            \n",
    "            R2_val_tf = np.around(R2(t_test, t_hat_test_tf), decimals=4)\n",
    "            \n",
    "            \n",
    "            results_large_df.loc[i] = [MSE_val_tf, R2_val_tf, MSE_val, R2_val, \n",
    "                                        own_model.nbf_parameters, hidden_size, eta, lmb]\n",
    "            results_large_df.to_csv(f\"{REPORT_DATA}{EX_C}results_large_{act_func}.csv\")\n",
    "            i+=1\n",
    "            \n",
    "    plot_save_NN_results(parameters=own_model.nbf_parameters, model_size=\"large\", eta_list=eta_list, lmb_list=lmb_list, \n",
    "                         heatmap_mtrx=heatmap_mtrx_MSE[n, :,:], heatmap_mtrx_tf=heatmap_mtrx_MSE_tf[n, :,:],\n",
    "                         path=f\"{REPORT_FIGURES}{EX_C}\", activation_type=act_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search  - Leaky RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_func = \"leaky_relu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_mtrx_MSE = np.zeros(shape=(hidden_sizes.shape[0], eta_list.shape[0], lmb_list.shape[0]))\n",
    "heatmap_mtrx_MSE_tf = np.zeros_like(heatmap_mtrx_MSE)\n",
    "\n",
    "parameters_best_MSE = {\"best_MSE\" : np.Inf, \"R2_at_best_MSE\" : np.Inf ,\"parameters\":0,\n",
    "                      \"neurons_first_hidden\":0, \"learning_rate\":0, \"lambda\":0, \"epochs\": epochs, \"batch_size\":batch_size}\n",
    "parameters_best_MSE_tf = {\"best_MSE\" : np.Inf, \"R2_at_best_MSE\" : np.Inf , \"parameters\":0,\n",
    "                          \"neurons_first_hidden\":0, \"learning_rate\":0, \"lambda\":0, \"epochs\": epochs, \"batch_size\":batch_size}\n",
    "best_models = {\"own_NN\":None, \"tf_NN\":None}\n",
    "\n",
    "results_simple_df = pd.DataFrame(columns=[\"MSE_tensorflow\",\"R2_tensorflow\",\"MSE_own_NN\",\"R2_own_NN\",\n",
    "                                          \"parameters_own_NN\",\"neurons_first_hidden\",\"learning_rate\",\n",
    "                                          \"regularization\"])\n",
    "# Grid search on eta and lambda \n",
    "i = 0\n",
    "for n, hidden_size in tqdm(enumerate(hidden_sizes)):\n",
    "    for y, lmb in enumerate(lmb_list):\n",
    "        for x, eta in enumerate(eta_list):\n",
    "            np.random.seed(4155)\n",
    "            own_model, tf_model = NN_simple_architecture(eta, nbf_features,\n",
    "                                                         problem_type=\"regression\",\n",
    "                                                         X_test=X_test.copy(), t_test=t_test.copy(),\n",
    "                                                         lmb=lmb, \n",
    "                                                         hidden_size=hidden_size, \n",
    "                                                         act_func=act_func)\n",
    "            \n",
    "            print(f\"Neurons in first hidden: {hidden_size} - Parameters: {own_model.nbf_parameters} - Lambda: {lmb} -Eta: {eta}\")\n",
    "            # Own model\n",
    "            train_losses, test_losses = own_model.fit(X_train.copy(), t_train.copy(), \n",
    "                                                            batch_size=batch_size, epochs=epochs,\n",
    "                                                            lr_scheduler=apply_lr_scheduler, verbose=False)\n",
    "            t_hat_test_own = own_model.predict(X_test.copy())\n",
    "            \n",
    "            MSE_val = np.around(MSE(t_test, t_hat_test_own), decimals=4)\n",
    "            R2_val = np.around(R2(t_test, t_hat_test_own), decimals=4)\n",
    "            heatmap_mtrx_MSE[n,y,x] = MSE_val\n",
    "\n",
    "            if parameters_best_MSE[\"best_MSE\"] > MSE_val:\n",
    "                print(f\"**New best MSE own NN**: {MSE_val}\")\n",
    "                best_models[\"own_NN\"] = own_model\n",
    "                parameters_best_MSE[\"best_MSE\"] = MSE_val\n",
    "                parameters_best_MSE[\"R2_at_best_MSE\"] = R2_val\n",
    "                parameters_best_MSE[\"parameters\"] = own_model.nbf_parameters\n",
    "                parameters_best_MSE[\"neurons_first_hidden\"] = hidden_size\n",
    "                parameters_best_MSE[\"learning_rate\"] = eta\n",
    "                parameters_best_MSE[\"lambda\"] = lmb\n",
    "                df = pd.DataFrame().from_dict(parameters_best_MSE, orient='index')\n",
    "                df.to_csv(f\"{REPORT_DATA}{EX_C}own_NN_best_training_small_{act_func}.csv\")\n",
    "                \n",
    "                plt.figure()\n",
    "                plt.plot(np.arange(epochs), train_losses, label=\"Train loss\")\n",
    "                plt.plot(np.arange(epochs), test_losses, label=\"Test loss\")\n",
    "                plt.title(f\"Best model own NN\\nMSE: {MSE_val}\\nNumber of parameters: {own_model.nbf_parameters}\\nLearning rate: {eta}\\nL2 Regularization: {lmb}\\nLeaky RELU\")\n",
    "                plt.xlabel(\"Epochs\")\n",
    "                plt.ylabel(\"Loss\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{REPORT_FIGURES}{EX_C}own_NN_best_training_small_{act_func}_lr_{eta}.pdf\")\n",
    "                \n",
    "                filename = f\"../data/models/best_small_model_{act_func}_mse_{np.around(MSE_val, decimals=4)}.pkl\"\n",
    "                save_model(own_model, filename)\n",
    "            \n",
    "                        \n",
    "            # Tensorflow\n",
    "            tf_model.fit(X_train.copy(), t_train.copy(), batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "            t_hat_test_tf = tf_model.predict(X_test.copy())\n",
    "            \n",
    "            MSE_val_tf = np.around(MSE(t_test, t_hat_test_tf), decimals=4)\n",
    "            heatmap_mtrx_MSE_tf[n, y,x] = MSE_val_tf\n",
    "\n",
    "            if parameters_best_MSE_tf[\"best_MSE\"] > MSE_val_tf:\n",
    "                print(f\"New best MSE tensorflow: {MSE_val_tf}\")\n",
    "                parameters_best_MSE_tf[\"best_MSE\"] = MSE_val_tf\n",
    "                parameters_best_MSE_tf[\"parameters\"] = own_model.nbf_parameters\n",
    "                parameters_best_MSE_tf[\"neurons_first_hidden\"] = hidden_size\n",
    "                parameters_best_MSE_tf[\"learning_rate\"] = eta\n",
    "                parameters_best_MSE_tf[\"lambda\"] = lmb\n",
    "                best_models[\"tf_NN\"] = tf_model\n",
    "            \n",
    "            R2_val_tf = np.around(R2(t_test, t_hat_test_tf), decimals=4)\n",
    "            \n",
    "            \n",
    "            results_simple_df.loc[i] = [MSE_val_tf, R2_val_tf, MSE_val, R2_val, \n",
    "                                        own_model.nbf_parameters, hidden_size, eta, lmb]\n",
    "            results_simple_df.to_csv(f\"{REPORT_DATA}{EX_C}results_small_{act_func}.csv\")\n",
    "            i+=1\n",
    "            \n",
    "    plot_save_NN_results(parameters=own_model.nbf_parameters, model_size=\"small\", eta_list=eta_list, lmb_list=lmb_list, \n",
    "                         heatmap_mtrx=heatmap_mtrx_MSE[n, :,:], heatmap_mtrx_tf=heatmap_mtrx_MSE_tf[n, :,:],\n",
    "                         path=f\"{REPORT_FIGURES}{EX_C}\", activation_type=act_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_mtrx_MSE = np.zeros(shape=(hidden_sizes.shape[0], eta_list.shape[0], lmb_list.shape[0]))\n",
    "heatmap_mtrx_MSE_tf = np.zeros_like(heatmap_mtrx_MSE)\n",
    "\n",
    "parameters_best_MSE = {\"best_MSE\" : np.Inf, \"R2_at_best_MSE\" : np.Inf ,\"parameters\":0,\n",
    "                      \"neurons_first_hidden\":0, \"learning_rate\":0, \"lambda\":0, \"epochs\": epochs, \"batch_size\":batch_size}\n",
    "parameters_best_MSE_tf = {\"best_MSE\" : np.Inf, \"R2_at_best_MSE\" : np.Inf , \"parameters\":0,\n",
    "                          \"neurons_first_hidden\":0, \"learning_rate\":0, \"lambda\":0, \"epochs\": epochs, \"batch_size\":batch_size}\n",
    "best_models = {\"own_NN\":None, \"tf_NN\":None}\n",
    "\n",
    "results_large_df = pd.DataFrame(columns=[\"MSE_tensorflow\",\"R2_tensorflow\",\"MSE_own_NN\",\"R2_own_NN\",\n",
    "                                          \"parameters_own_NN\",\"neurons_first_hidden\",\"learning_rate\",\n",
    "                                          \"regularization\"])\n",
    "# Grid search on eta and lambda \n",
    "i = 0\n",
    "for n, hidden_size in tqdm(enumerate(hidden_sizes)):\n",
    "    for y, lmb in enumerate(lmb_list):\n",
    "        for x, eta in enumerate(eta_list):\n",
    "            np.random.seed(4155)\n",
    "            own_model, tf_model = NN_large_architecture(eta, nbf_features,\n",
    "                                                         problem_type=\"regression\",\n",
    "                                                         X_test=X_test.copy(), t_test=t_test.copy(),\n",
    "                                                         lmb=lmb, \n",
    "                                                         hidden_size=hidden_size, \n",
    "                                                         act_func=act_func)\n",
    "            \n",
    "            print(f\"Neurons in first hidden: {hidden_size} - Parameters: {own_model.nbf_parameters} - Lambda: {lmb} -Eta: {eta}\")\n",
    "            # Own model\n",
    "            train_losses, test_losses = own_model.fit(X_train.copy(), t_train.copy(), \n",
    "                                                            batch_size=batch_size, epochs=epochs,\n",
    "                                                            lr_scheduler=apply_lr_scheduler, verbose=False)\n",
    "            t_hat_test_own = own_model.predict(X_test.copy())\n",
    "            \n",
    "            MSE_val = np.around(MSE(t_test, t_hat_test_own), decimals=4)\n",
    "            R2_val = np.around(R2(t_test, t_hat_test_own), decimals=4)\n",
    "            heatmap_mtrx_MSE[n,y,x] = MSE_val\n",
    "\n",
    "            if parameters_best_MSE[\"best_MSE\"] > MSE_val:\n",
    "                print(f\"**New best MSE own NN**: {MSE_val}\")\n",
    "                best_models[\"own_NN\"] = own_model\n",
    "                parameters_best_MSE[\"best_MSE\"] = MSE_val\n",
    "                parameters_best_MSE[\"R2_at_best_MSE\"] = R2_val\n",
    "                parameters_best_MSE[\"parameters\"] = own_model.nbf_parameters\n",
    "                parameters_best_MSE[\"neurons_first_hidden\"] = hidden_size\n",
    "                parameters_best_MSE[\"learning_rate\"] = eta\n",
    "                parameters_best_MSE[\"lambda\"] = lmb\n",
    "                df = pd.DataFrame().from_dict(parameters_best_MSE, orient='index')\n",
    "                df.to_csv(f\"{REPORT_DATA}{EX_C}own_NN_best_training_large_{act_func}.csv\")\n",
    "                \n",
    "                plt.figure()\n",
    "                plt.plot(np.arange(epochs), train_losses, label=\"Train loss\")\n",
    "                plt.plot(np.arange(epochs), test_losses, label=\"Test loss\")\n",
    "                plt.title(f\"Best model own NN\\nMSE: {MSE_val}\\nNumber of parameters: {own_model.nbf_parameters}\\nLearning rate: {eta}\\nL2 Regularization: {lmb}\\nLeaky RELU\")\n",
    "                plt.xlabel(\"Epochs\")\n",
    "                plt.ylabel(\"Loss\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{REPORT_FIGURES}{EX_C}own_NN_best_training_large_{act_func}_lr_{eta}.pdf\")\n",
    "                \n",
    "                filename = f\"../data/models/best_large_model_{act_func}_mse_{np.around(MSE_val, decimals=4)}.pkl\"\n",
    "                save_model(own_model, filename)\n",
    "            \n",
    "                        \n",
    "            # Tensorflow\n",
    "            tf_model.fit(X_train.copy(), t_train.copy(), batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "            t_hat_test_tf = tf_model.predict(X_test.copy())\n",
    "            \n",
    "            MSE_val_tf = np.around(MSE(t_test, t_hat_test_tf), decimals=4)\n",
    "            heatmap_mtrx_MSE_tf[n, y,x] = MSE_val_tf\n",
    "\n",
    "            if parameters_best_MSE_tf[\"best_MSE\"] > MSE_val_tf:\n",
    "                print(f\"New best MSE tensorflow: {MSE_val_tf}\")\n",
    "                parameters_best_MSE_tf[\"best_MSE\"] = MSE_val_tf\n",
    "                parameters_best_MSE_tf[\"parameters\"] = own_model.nbf_parameters\n",
    "                parameters_best_MSE_tf[\"neurons_first_hidden\"] = hidden_size\n",
    "                parameters_best_MSE_tf[\"learning_rate\"] = eta\n",
    "                parameters_best_MSE_tf[\"lambda\"] = lmb\n",
    "                best_models[\"tf_NN\"] = tf_model\n",
    "            \n",
    "            R2_val_tf = np.around(R2(t_test, t_hat_test_tf), decimals=4)\n",
    "            \n",
    "            \n",
    "            results_large_df.loc[i] = [MSE_val_tf, R2_val_tf, MSE_val, R2_val, \n",
    "                                        own_model.nbf_parameters, hidden_size, eta, lmb]\n",
    "            results_large_df.to_csv(f\"{REPORT_DATA}{EX_C}results_large_{act_func}.csv\")\n",
    "            i+=1\n",
    "            \n",
    "    plot_save_NN_results(parameters=own_model.nbf_parameters, model_size=\"large\", eta_list=eta_list, lmb_list=lmb_list, \n",
    "                         heatmap_mtrx=heatmap_mtrx_MSE[n, :,:], heatmap_mtrx_tf=heatmap_mtrx_MSE_tf[n, :,:],\n",
    "                         path=f\"{REPORT_FIGURES}{EX_C}\", activation_type=act_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation on best model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/report_data/NN_optimal_parameters_large_leaky_relu.csv\").T\n",
    "\n",
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1: , :]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 1\n",
    "X = create_X(x,y, degree)\n",
    "X = X[:,1:]\n",
    "\n",
    "folds = 7\n",
    "cross_val_results = cross_val(folds, X=X,z=z, eta=0.05,batch_size=300, lmb=0, epochs=100, hidden_size=32, random_state=4155)\n",
    "cross_val_df = pd.DataFrame(data = cross_val_results, columns=['MSE'])\n",
    "cross_val_df\n",
    "cross_val_df.loc['mean'] = cross_val_df[\"MSE\"].mean()\n",
    "#cross_val_df.to_csv(f\"{REPORT_DATA}{EX_C}cross_val.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "664767e83c7b06364e16bf4bb7694b1f8b5947c6e3e0843db3deeed47f8be06a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('fysstk1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
